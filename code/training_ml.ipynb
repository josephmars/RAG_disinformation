{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (80, 2)\n",
      "                                                Text  Disinformation\n",
      "0  explainer blood treasure and chaos the cost of...               0\n",
      "1  declared that Russia wants to resolve the situ...               1\n",
      "2  Deputy persecution of the priests of the UOC a...               1\n",
      "3  VSU deliberately do not remove the bodies of t...               1\n",
      "4  Zakharova announced EU plans to “train terrori...               1\n",
      "test shape: (20, 2)\n",
      "                                                Text  Disinformation\n",
      "0  treasure the usa must inevitably leave europe ...               1\n",
      "1  moscow warns west against ‘playing with fire’ ...               1\n",
      "2  dead soldiers apu end up in europenbsp mdash b...               1\n",
      "3  the preparation of a provocation of Kyiv at th...               1\n",
      "4  ukraine refugees face uncertainty and precarit...               0\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../data/train.csv')\n",
    "print(f'train shape: {train.shape}')\n",
    "print(train.head())\n",
    "test = pd.read_csv('../data/test.csv')\n",
    "print(f'test shape: {test.shape}')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (RF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train rf classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifier = RandomForestClassifier()\n",
    "model = make_pipeline(vectorizer, classifier)\n",
    "model.fit(train['Text'], train['Disinformation'])\n",
    "labels = model.predict(test['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84        10\n",
      "           1       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.85        20\n",
      "   macro avg       0.85      0.85      0.85        20\n",
      "weighted avg       0.85      0.85      0.85        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(classification_report(test['Disinformation'], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/rf_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train svm classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifier = svm.SVC()\n",
    "model = make_pipeline(vectorizer, classifier)\n",
    "model.fit(train['Text'], train['Disinformation'])\n",
    "labels = model.predict(test['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        20\n",
      "   macro avg       1.00      1.00      1.00        20\n",
      "weighted avg       1.00      1.00      1.00        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(classification_report(test['Disinformation'], labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train svm classifier\n",
    "vectorizer = TfidfVectorizer()\n",
    "classifier = MultinomialNB()\n",
    "model = make_pipeline(vectorizer, classifier)\n",
    "model.fit(train['Text'], train['Disinformation'])\n",
    "labels = model.predict(test['Text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(classification_report(test['Disinformation'], labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-disinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
